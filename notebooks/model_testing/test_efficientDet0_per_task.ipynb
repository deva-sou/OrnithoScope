{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tasks = pickle.load( open( \"/home/acarlier/code/OrnithoScope/data/pickles/list_tasks.p\", \"rb\" ) )\n",
    "model_path = '/home/acarlier/code/OrnithoScope/saved_models/model_efficientDet0.tflite'\n",
    "input_csv_path = '/home/acarlier/code/OrnithoScope/data/csv/input.csv'\n",
    "pickle_tasks_path = '/home/acarlier/code/OrnithoScope/data/pickles/tasks/'\n",
    "columns_names = [\"split_value\", \"file_path\", \"label\",\n",
    "                      \"x_min\", \"y_min\", \"empty_1\", \"empty_2\",\n",
    "                      \"x_max\", \"y_max\", \"empty_3\"]\n",
    "#output_images_directory = '/home/acarlier/code/data_ornitho/output_images/'\n",
    "#comparaison_images_directory = '/home/acarlier/code/data_ornitho/comparaison_verite_terrain/comparaison_efficientDet1/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tasks df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_per_tasks(pickle_tasks_path):\n",
    "    dfs = []\n",
    "    pickle_tasks_files = os.listdir(pickle_tasks_path)\n",
    "    for file in pickle_tasks_files:\n",
    "        dfs.append(pickle.load( open( f\"{pickle_tasks_path}{file}\", \"rb\" ) ))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_df_per_tasks(pickle_tasks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_from_input():\n",
    "    input = pd.read_csv('/home/acarlier/code/OrnithoScope/data/csv/input.csv', names = [\"split_value\", \"file_path\", \"label\",\n",
    "                      \"x_min\", \"y_min\", \"empty_1\", \"empty_2\",\n",
    "                      \"x_max\", \"y_max\", \"empty_3\"])\n",
    "    return input[\"label\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = get_classes_from_input()\n",
    "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, input_size):\n",
    "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
    "  img = tf.io.read_file(image_path)\n",
    "  img = tf.io.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "  original_image = img\n",
    "  resized_img = tf.image.resize(img, input_size)\n",
    "  resized_img = resized_img[tf.newaxis, :]\n",
    "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
    "  #print(tf.shape(resized_img))\n",
    "  return resized_img, original_image\n",
    "\n",
    "def preprocess_images(image_paths, input_size):\n",
    "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
    "  img = tf.io.read_file(image_paths[0])\n",
    "  img = tf.io.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "  resized_img = tf.image.resize(img, input_size)\n",
    "  resized_img = resized_img[tf.newaxis, :]\n",
    "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
    "  \n",
    "  resized_imgs = resized_img\n",
    "  \n",
    "  for i in range(1,len(image_paths)):\n",
    "    img = tf.io.read_file(image_paths[i])\n",
    "    img = tf.io.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "    resized_img = tf.image.resize(img, input_size)\n",
    "    resized_img = resized_img[tf.newaxis, :]\n",
    "    resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
    "    \n",
    "    resized_imgs = tf.concat([resized_imgs, resized_img], axis=0)\n",
    "    #print(tf.shape(resized_imgs))\n",
    "    \n",
    "  return resized_imgs\n",
    "\n",
    "\n",
    "def detect_objects(interpreter, image, threshold):\n",
    "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
    "\n",
    "  signature_fn = interpreter.get_signature_runner()\n",
    "  #print(\"avant modèle\")\n",
    "  # Feed the input image to the model\n",
    "  output = signature_fn(images=image)\n",
    "  #interpreter.set_tensor(0, image)\n",
    "  #interpreter.invoke()\n",
    "  #print(\"après modèle\")\n",
    "  \n",
    "  # Get all outputs from the model\n",
    "  count = int(np.squeeze(output['output_0']))\n",
    "  scores = np.squeeze(output['output_1'])\n",
    "  classes = np.squeeze(output['output_2'])\n",
    "  boxes = np.squeeze(output['output_3'])\n",
    "\n",
    "  results = []\n",
    "  for i in range(count):\n",
    "    if scores[i] >= threshold:\n",
    "      result = {\n",
    "        'bounding_box': boxes[i],\n",
    "        'class_id': classes[i],\n",
    "        'score': scores[i]\n",
    "      }\n",
    "      results.append(result)\n",
    "  return results\n",
    "\n",
    "\n",
    "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
    "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
    "  # Load the input shape required by the model\n",
    "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
    "  print(input_height, input_width)\n",
    "  #print(\"interpreter\")\n",
    "  \n",
    "  # Load the input image and preprocess it\n",
    "  preprocessed_image, _ = preprocess_image(\n",
    "      image_path,\n",
    "      (input_height, input_width)\n",
    "    )\n",
    "  #print(\"preprocessing\")\n",
    "  \n",
    "  # Run object detection on the input image\n",
    "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
    "  \n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/acarlier/OrnithoMate/p0133_bird_data/raw_data/task_20210611_Lab/2021-06-11-13-44-43.jpg\n",
      "411\n"
     ]
    }
   ],
   "source": [
    "def get_test_images(df):\n",
    "    list_image_test = df[\"file_path\"].unique().tolist() # return all unique file_path to test, no prediction on two same image\n",
    "    return list_image_test\n",
    "loi = get_test_images(dfs[0])\n",
    "print(loi[0])\n",
    "print(len(loi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from model\n",
    "def prediction_test_dataset(df):\n",
    "    results = []\n",
    "    list_of_images = get_test_images(df)\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    #list_of_images = ['/home/acarlier/code/test/2021-06-11-13-44-43.jpg']\n",
    "    # Load the TFLite model\n",
    "    print(len(list_of_images),' to predict')\n",
    "    for img in list_of_images[:2]:\n",
    "        if list_of_images.index(img)%100 == 0:\n",
    "            print(list_of_images.index(img))\n",
    "        img_name = img.split('/')[-1]\n",
    "        # file_path = '{}{}'.format(output_images_directory, img_name)\n",
    "        # if os.path.exists(file_path):\n",
    "        #     list_of_images.remove(img)\n",
    "        #     #print(len(list_of_images),' remaining')\n",
    "        # else:\n",
    "        INPUT_IMAGE_URL = img #@param {type:\"string\"}\n",
    "        DETECTION_THRESHOLD = 0.3 #@param {type:\"number\"}\n",
    "        TEMP_FILE = img\n",
    "        FILE_NAME = TEMP_FILE.split(\"/\")[-1]\n",
    "        #print('test1.2 : ok')\n",
    "        #!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\n",
    "        #!wget -q -O $INPUT_IMAGE_URL\n",
    "        #print('test1.3 : ok')\n",
    "        try:\n",
    "            with open(TEMP_FILE) as file:\n",
    "                #im = Image.open(TEMP_FILE)\n",
    "                #im.thumbnail((512, 512), Image.ANTIALIAS)\n",
    "                #im.save(TEMP_FILE, 'JPEG')\n",
    "                # Run inference and draw detection result on the local copy of the original file\n",
    "                result = run_odt_and_draw_results(\n",
    "                    TEMP_FILE,\n",
    "                    interpreter,\n",
    "                    threshold=DETECTION_THRESHOLD\n",
    "                )\n",
    "                results.append(result)\n",
    "                # Show the detection result\n",
    "                #Image.fromarray(detection_result_image)\n",
    "                #result = Image.fromarray(detection_result_image)\n",
    "                #result.save(\"{}{}\".format(output_images_directory, FILE_NAME), 'JPEG')\n",
    "                #result.show()\n",
    "        except OSError as e:\n",
    "            print(e.errno)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prediction results with pickles\n",
    "# results_predictions = prediction_test_dataset()\n",
    "# pickle.dump(results_predictions, open( \"/home/acarlier/code/OrnithoScope/saved_models/results_EfficientDet0.p\", \"wb\" ) )\n",
    "\n",
    "# # load prediction results with pickles \n",
    "# #results_predictions = pickle.load( open( \"/home/acarlier/code/OrnithoScope/saved_models/results_EfficientDet1.p\", \"rb\" ) )\n",
    "\n",
    "\n",
    "# classes = get_classes_from_input()\n",
    "# print(len(results_predictions))\n",
    "# print(classes)\n",
    "# results_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n",
      "328  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n",
      "400  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n",
      "805  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n",
      "196  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n",
      "169  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n",
      "228  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n",
      "979  to predict\n",
      "0\n",
      "320 320\n",
      "320 320\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    task_name = df['task_name'].unique()[0]\n",
    "    df = df.loc[:, ~df.columns.isin(['task_name', 'Site', 'Day','Day2'])]\n",
    "    results_predictions = prediction_test_dataset(df)\n",
    "    pickle.dump(results_predictions, open( f\"/home/acarlier/code/OrnithoScope/saved_models/tasks/{task_name}.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19c3081fe3265570dc101441fe38429c8bca377ba2301426b88b33379fbbcf85"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ornithoScope_virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
