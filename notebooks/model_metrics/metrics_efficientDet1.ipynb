{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/deva/code/OrnithoScope/saved_models/model_efficientDet1.tflite'\n",
    "input_csv_path = '/home/deva/code/OrnithoScope/data/input.csv'\n",
    "columns_names = [\"split_value\", \"file_path\", \"label\",\n",
    "                      \"x_min\", \"y_min\", \"empty_1\", \"empty_2\",\n",
    "                      \"x_max\", \"y_max\", \"empty_3\"]\n",
    "output_images_directory = '/home/deva/code/data_ornitho/output_images/test_pickle/'\n",
    "comparaison_images_directory = '/home/deva/code/data_ornitho/comparaison_verite_terrain/comparaison_efficientDet1/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load the trained TFLite model and define some visualization functions\n",
    "\n",
    "def get_classes_from_input():\n",
    "    input = pd.read_csv(input_csv_path, names = columns_names)\n",
    "    return input[\"label\"].unique().tolist()\n",
    "\n",
    "# Load the labels into a list\n",
    "classes = get_classes_from_input()\n",
    "# Define a list of colors for visualization\n",
    "COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)\n",
    "\n",
    "def preprocess_image(image_path, input_size):\n",
    "  \"\"\"Preprocess the input image to feed to the TFLite model\"\"\"\n",
    "  img = tf.io.read_file(image_path)\n",
    "  img = tf.io.decode_image(img, channels=3)\n",
    "  img = tf.image.convert_image_dtype(img, tf.uint8)\n",
    "  original_image = img\n",
    "  resized_img = tf.image.resize(img, input_size)\n",
    "  resized_img = resized_img[tf.newaxis, :]\n",
    "  resized_img = tf.cast(resized_img, dtype=tf.uint8)\n",
    "  return resized_img, original_image\n",
    "\n",
    "\n",
    "def detect_objects(interpreter, image, threshold):\n",
    "  \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n",
    "\n",
    "  signature_fn = interpreter.get_signature_runner()\n",
    "\n",
    "  # Feed the input image to the model\n",
    "  output = signature_fn(images=image)\n",
    "\n",
    "  # Get all outputs from the model\n",
    "  count = int(np.squeeze(output['output_0']))\n",
    "  scores = np.squeeze(output['output_1'])\n",
    "  classes = np.squeeze(output['output_2'])\n",
    "  boxes = np.squeeze(output['output_3'])\n",
    "\n",
    "  results = []\n",
    "  for i in range(count):\n",
    "    if scores[i] >= threshold:\n",
    "      result = {\n",
    "        'bounding_box': boxes[i],\n",
    "        'class_id': classes[i],\n",
    "        'score': scores[i]\n",
    "      }\n",
    "      results.append(result)\n",
    "  return results\n",
    "\n",
    "\n",
    "def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):\n",
    "  \"\"\"Run object detection on the input image and draw the detection results\"\"\"\n",
    "  # Load the input shape required by the model\n",
    "  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']\n",
    "\n",
    "  # Load the input image and preprocess it\n",
    "  preprocessed_image, original_image = preprocess_image(\n",
    "      image_path,\n",
    "      (input_height, input_width)\n",
    "    )\n",
    "\n",
    "  # Run object detection on the input image\n",
    "  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)\n",
    "\n",
    "  # Plot the detection results on the input image\n",
    "  original_image_np = original_image.numpy().astype(np.uint8)\n",
    "  for obj in results:\n",
    "    # Convert the object bounding box from relative coordinates to absolute\n",
    "    # coordinates based on the original image resolution\n",
    "    ymin, xmin, ymax, xmax = obj['bounding_box']\n",
    "    xmin = int(xmin * original_image_np.shape[1])\n",
    "    xmax = int(xmax * original_image_np.shape[1])\n",
    "    ymin = int(ymin * original_image_np.shape[0])\n",
    "    ymax = int(ymax * original_image_np.shape[0])\n",
    "\n",
    "    # Find the class index of the current object\n",
    "    class_id = int(obj['class_id'])\n",
    "\n",
    "    # Draw the bounding box and label on the image\n",
    "    color = [int(c) for c in COLORS[class_id]]\n",
    "    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "    # Make adjustments to make the label visible for all objects\n",
    "    y = ymin - 15 if ymin - 15 > 15 else ymin + 15\n",
    "    label = \"{}: {:.0f}%\".format(classes[class_id], obj['score'] * 100)\n",
    "    cv2.putText(original_image_np, label, (xmin, y),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "  # Return the final image\n",
    "  original_uint8 = original_image_np.astype(np.uint8)\n",
    "  return original_uint8, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/deva/code/data_ornitho/raw_data/task_2021-03-01_09/20210301-090002_(13.0).jpg\n",
      "3516\n"
     ]
    }
   ],
   "source": [
    "def get_test_images():\n",
    "    input = pd.read_csv(input_csv_path, names = columns_names)\n",
    "    test_dataset = input.loc[input['split_value'] == 'TEST']\n",
    "    list_image_test = test_dataset[\"file_path\"].unique().tolist() # return all unique file_path to test, no prediction on two same image\n",
    "    return list_image_test\n",
    "loi = get_test_images()\n",
    "print(loi[0])\n",
    "print(len(loi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_test_dataset():\n",
    "    results = []\n",
    "    list_of_images = get_test_images()\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    #list_of_images = ['/home/acarlier/code/test/2021-06-11-13-44-43.jpg']\n",
    "    # Load the TFLite model\n",
    "    print(len(list_of_images),' to predict')\n",
    "    for img in list_of_images[:10]:\n",
    "        img_name = img.split('/')[-1]\n",
    "        file_path = '{}{}'.format(output_images_directory, img_name)\n",
    "        if os.path.exists(file_path):\n",
    "            list_of_images.remove(img)\n",
    "            print(len(list_of_images),' remaining')\n",
    "        else:\n",
    "            INPUT_IMAGE_URL = img #@param {type:\"string\"}\n",
    "            DETECTION_THRESHOLD = 0.3 #@param {type:\"number\"}\n",
    "            TEMP_FILE = img\n",
    "            FILE_NAME = TEMP_FILE.split(\"/\")[-1]\n",
    "            #print('test1.2 : ok')\n",
    "            #!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\n",
    "            #!wget -q -O $INPUT_IMAGE_URL\n",
    "            #print('test1.3 : ok')\n",
    "            try:\n",
    "                with open(TEMP_FILE) as file:\n",
    "                    im = Image.open(TEMP_FILE)\n",
    "                    im.thumbnail((512, 512), Image.ANTIALIAS)\n",
    "                    im.save(TEMP_FILE, 'JPEG')\n",
    "                    # Run inference and draw detection result on the local copy of the original file\n",
    "                    detection_result_image, result = run_odt_and_draw_results(\n",
    "                        TEMP_FILE,\n",
    "                        interpreter,\n",
    "                        threshold=DETECTION_THRESHOLD\n",
    "                    )\n",
    "                    results.append(result)\n",
    "                    # Show the detection result\n",
    "                    #Image.fromarray(detection_result_image)\n",
    "                    #result = Image.fromarray(detection_result_image)\n",
    "                    #result.save(\"{}{}\".format(output_images_directory, FILE_NAME), 'JPEG')\n",
    "                    #result.show()\n",
    "            except OSError as e:\n",
    "                print(e.errno)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3516  to predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2022-03-18 16:06:00.093618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.099374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.099501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.099833: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-18 16:06:00.100263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.100378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.100470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.457572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.457705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.457801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-18 16:06:00.457882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5548 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "results = prediction_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['MESCHA', 'SITTOR', 'MESBLE', 'MESNON', 'PINARB', 'ACCMOU', 'ROUGOR', 'VEREUR', 'MOIDOM', 'TOUTUR', 'ECUROU', 'PIEBAV', 'MULGRI', 'CAMPAG', 'MESNOI', 'MESHUP']\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "print(get_classes_from_input())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( results, open( \"/home/deva/code/OrnithoScope/saved_models/results.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bounding_box': array([0.09921169, 0.25329775, 0.68758965, 0.4730904 ], dtype=float32),\n",
       "   'class_id': 7.0,\n",
       "   'score': 0.6484375}],\n",
       " [{'bounding_box': array([0.4092438, 0.5277908, 1.0296512, 0.7281122], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.375}],\n",
       " [{'bounding_box': array([0.5509056, 0.5129066, 0.9888495, 0.9870934], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.9296875}],\n",
       " [{'bounding_box': array([0.39843464, 0.30333823, 0.6451436 , 0.5669474 ], dtype=float32),\n",
       "   'class_id': 7.0,\n",
       "   'score': 0.84765625}],\n",
       " [],\n",
       " [{'bounding_box': array([0.41062987, 0.13668333, 0.8865938 , 0.38762027], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.91796875}],\n",
       " [{'bounding_box': array([0.46652228, 0.13806312, 0.668348  , 0.5108628 ], dtype=float32),\n",
       "   'class_id': 7.0,\n",
       "   'score': 0.8125},\n",
       "  {'bounding_box': array([0.8450288, 0.8830899, 0.993529 , 0.998536 ], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.76953125}],\n",
       " [{'bounding_box': array([0.43046698, 0.2513759 , 0.6197371 , 0.51850164], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.8984375}],\n",
       " [{'bounding_box': array([0.38969195, 0.09086055, 0.7972007 , 0.4293654 ], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.88671875}],\n",
       " [{'bounding_box': array([0.3573898 , 0.27911854, 0.62606126, 0.5624156 ], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.8359375}]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_from_prediction(list_of_results, df_input_test, list_of_classes):\n",
    "    class_metrics = []\n",
    "    for classes in list_of_classes:\n",
    "        class_metrics.append({'TP':0, 'FP':0, 'FN':0})\n",
    "    \n",
    "    total_correct_detections = 0\n",
    "    total_incorect_detections = 0\n",
    "    \n",
    "\n",
    "    return class_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_value</th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>empty_1</th>\n",
       "      <th>empty_2</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>empty_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>TEST</td>\n",
       "      <td>/home/deva/code/data_ornitho/raw_data/task_202...</td>\n",
       "      <td>VEREUR</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4593</td>\n",
       "      <td>0.7075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     split_value                                          file_path   label  \\\n",
       "2124        TEST  /home/deva/code/data_ornitho/raw_data/task_202...  VEREUR   \n",
       "\n",
       "       x_min   y_min  empty_1  empty_2   x_max   y_max  empty_3  \n",
       "2124  0.2543  0.0371      NaN      NaN  0.4593  0.7075      NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = pd.read_csv('/home/deva/code/OrnithoScope/data/input.csv', names = columns_names)\n",
    "df_input_test = df_input[df_input[\"split_value\"] == 'TEST']\n",
    "df_input_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bounding_box': array([0.09921169, 0.25329775, 0.68758965, 0.4730904 ], dtype=float32),\n",
       "   'class_id': 7.0,\n",
       "   'score': 0.6484375}],\n",
       " [{'bounding_box': array([0.4092438, 0.5277908, 1.0296512, 0.7281122], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.375}],\n",
       " [{'bounding_box': array([0.5509056, 0.5129066, 0.9888495, 0.9870934], dtype=float32),\n",
       "   'class_id': 0.0,\n",
       "   'score': 0.9296875}]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_metrics = get_precision_recall_from_prediction(results,df_input_test,get_classes_from_input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(class_metrics, list_of_species):\n",
    "    for i in range(0, len(class_metrics)):\n",
    "        TP = class_metrics[i]['TP']\n",
    "        FP = class_metrics[i]['FP']\n",
    "        FN = class_metrics[i]['FN']\n",
    "        print(f\"{list_of_species[i]} - TP : {TP} FP : {FP} FN : {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESCHA - TP : 0 FP : 0 FN : 0\n",
      "SITTOR - TP : 0 FP : 0 FN : 0\n",
      "MESBLE - TP : 0 FP : 0 FN : 0\n",
      "MESNON - TP : 0 FP : 0 FN : 0\n",
      "PINARB - TP : 0 FP : 0 FN : 0\n",
      "ACCMOU - TP : 0 FP : 0 FN : 0\n",
      "ROUGOR - TP : 0 FP : 0 FN : 0\n",
      "VEREUR - TP : 0 FP : 0 FN : 0\n",
      "MOIDOM - TP : 0 FP : 0 FN : 0\n",
      "TOUTUR - TP : 0 FP : 0 FN : 0\n",
      "ECUROU - TP : 0 FP : 0 FN : 0\n",
      "PIEBAV - TP : 0 FP : 0 FN : 0\n",
      "MULGRI - TP : 0 FP : 0 FN : 0\n",
      "CAMPAG - TP : 0 FP : 0 FN : 0\n",
      "MESNOI - TP : 0 FP : 0 FN : 0\n",
      "MESHUP - TP : 0 FP : 0 FN : 0\n"
     ]
    }
   ],
   "source": [
    "print_results(class_metrics, get_classes_from_input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19c3081fe3265570dc101441fe38429c8bca377ba2301426b88b33379fbbcf85"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ornithoScope_virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
